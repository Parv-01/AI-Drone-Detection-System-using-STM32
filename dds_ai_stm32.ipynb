{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5a53ff-2aad-49d7-91f2-9bbbe9e81edd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    image_dir = os.path.join(data_dir, 'images')\n",
    "    label_dir = os.path.join(data_dir, 'labels')\n",
    "    \n",
    "    for image_name in os.listdir(image_dir):\n",
    "        # Load and preprocess image\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = image / 255.0\n",
    "        images.append(image)\n",
    "        \n",
    "        # Load corresponding label\n",
    "        label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "        label_path = os.path.join(label_dir, label_name)\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            label_lines = f.readlines()\n",
    "            # Extract class IDs from each line\n",
    "            class_ids = [int(line.split()[0]) for line in label_lines]\n",
    "            \n",
    "            # For binary classification, we'll consider an image positive if it contains any drone\n",
    "            label = 1 if 1 in class_ids else 0\n",
    "        \n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_dir = r\"C:\\Users\\Intern13\\Desktop\\project\\qtm\\dataset\\yolo_dataset_v3_negative\\train\"\n",
    "X, y = load_and_preprocess_data(data_dir)\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f759bdd-2063-4c0a-a798-a8b0177f1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # Changed to sigmoid for binary classification\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Step 3: Model Compilation\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Changed to binary_crossentropy\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Step 4: Model Training\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Step 5: Model Evonooo\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "# Step 6: Convert model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('drone_detection_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "# Step 7: Quantize the model (optional, for better performance on STM board)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized TFLite model\n",
    "with open('drone_detection_model_quantized.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)    \n",
    "\n",
    "# Step 8: Test the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def predict_tflite(image):\n",
    "    input_data = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return output_data[0][0]\n",
    "\n",
    "# Test the TFLite model on a sample image\n",
    "sample_image = X_val[0]\n",
    "prediction = predict_tflite(sample_image)\n",
    "print(f\"TFLite model prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21445b75-0f3b-4a42-88d8-4a16a58b133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a45dc-3136-46be-b50c-304b8bd3bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
